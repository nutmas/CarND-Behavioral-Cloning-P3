{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LOAD DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv # for csv file import\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_file_data(file_path, header=False):\n",
    "    # function to read in data from driving_log.csv\n",
    "    \n",
    "    lines = []\n",
    "    with open(file_path + '/driving_log.csv') as csvfile:\n",
    "        reader = csv.reader(csvfile)\n",
    "        # if header is set to true then skip first line of csv\n",
    "        if header:\n",
    "            # if header exists iterate to next item in list, returns -1 if exhausted\n",
    "            next(reader, -1)\n",
    "        for line in reader:\n",
    "            # loop through reader appending each line to lines array\n",
    "            lines.append(line)\n",
    "    return lines\n",
    "\n",
    "\n",
    "centre_camera = 0    \n",
    "left_camera = 1\n",
    "right_camera = 2\n",
    "steering_angle = 3\n",
    "\n",
    "\n",
    "\n",
    "new_x = get_file_data('./my_driving')\n",
    "udacity_x = get_file_data('./data')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steering_angles = []\n",
    "camera_images = []\n",
    "\n",
    "source_path = './my_driving/IMG/'\n",
    "\n",
    "for line in new_x[0:]:\n",
    "\n",
    "    # get steering angle from csv 4th element of CSV and cast as float for this point in time\n",
    "    #measurement = float(line[3])\n",
    "    steering_centre = float(line[steering_angle])\n",
    "\n",
    "    # create adjusted steering measurements for the side camera images\n",
    "    correction = 0.25  # this is a parameter to tune\n",
    "    steering_left = steering_centre + correction\n",
    "    steering_right = steering_centre - correction\n",
    "\n",
    "    img_centre = cv2.imread(source_path + line[centre_camera].split('/')[-1])\n",
    "    img_left = cv2.imread(source_path + line[left_camera].split('/')[-1])\n",
    "    img_right = cv2.imread(source_path + line[right_camera].split('/')[-1])\n",
    "\n",
    "    #img_centre_hsv = cv2.cvtColor(img_centre, cv2.COLOR_BGR2HSV)\n",
    "    #img_left_hsv = cv2.cvtColor(img_left, cv2.COLOR_BGR2HSV)\n",
    "    #img_right_hsv = cv2.cvtColor(img_right, cv2.COLOR_BGR2HSV)\n",
    "    \n",
    "    #img_centre_yuv = cv2.cvtColor(img_centre, cv2.COLOR_BGR2YUV)\n",
    "    #img_left_yuv = cv2.cvtColor(img_left, cv2.COLOR_BGR2YUV)\n",
    "    #img_right_yuv = cv2.cvtColor(img_right, cv2.COLOR_BGR2YUV)\n",
    "\n",
    "    # add images and angles to data set\n",
    "    camera_images.append(img_centre)\n",
    "    camera_images.append(img_left)\n",
    "    camera_images.append(img_right)\n",
    "\n",
    "    steering_angles.append(steering_centre)\n",
    "    steering_angles.append(steering_left)\n",
    "    steering_angles.append(steering_right)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert arrays to numpy arrays for keras\n",
    "X_train = np.array(camera_images)\n",
    "y_train = np.array(steering_angles)\n",
    "\n",
    "\n",
    "print(X_train[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_timestamps = []\n",
    "my_ms_timestamp = []\n",
    "my_steering_angles = []\n",
    "\n",
    "for y in new_x:\n",
    "    my_steering_angles.append(np.float((y[steering_angle])))\n",
    "    # add file name from centre camerea image to get timestamp\n",
    "    my_timestamps.append(y[centre_camera].split('/')[-1])\n",
    "    \n",
    "    # get the file name from centre camera image with no file extension\n",
    "    filename_noext = (os.path.splitext(os.path.basename(y[centre_camera]))[0])\n",
    "    # extract hours, mins, secs and msecs from filename\n",
    "    h_m_s_ms = filename_noext.split('_')[-4:]\n",
    "    \n",
    "    # process time to msecs\n",
    "    mins = np.float(h_m_s_ms[0]) * 60 + np.float(h_m_s_ms[1])\n",
    "    secs = mins * 60 + np.float(h_m_s_ms[2])\n",
    "    msecs = secs * 1000 + np.float(h_m_s_ms [3])\n",
    "    \n",
    "    # append msecs to array\n",
    "    my_ms_timestamp.append(int(msecs))\n",
    "\n",
    "# create numpy array from array\n",
    "np_my_steering_angles = np.array(my_steering_angles)\n",
    "\n",
    "\n",
    "udacity_steering_angles = []\n",
    "udacity_timestamps = []\n",
    "udacity_ms_timestamp = []\n",
    "\n",
    "for y in udacity_x:\n",
    "    udacity_steering_angles.append(np.float((y[steering_angle])))\n",
    "    \n",
    "    # add file name from centre camerea image to get timestamp\n",
    "    udacity_timestamps.append(y[centre_camera].split('/')[-1])\n",
    "    \n",
    "    # get the file name from centre camera image with no file extension\n",
    "    filename_noext = (os.path.splitext(os.path.basename(y[centre_camera]))[0])\n",
    "    # extract hours, mins, secs and msecs from filename\n",
    "    h_m_s_ms = filename_noext.split('_')[-4:]\n",
    "    \n",
    "    # process time to msecs\n",
    "    mins = np.float(h_m_s_ms[0]) * 60 + np.float(h_m_s_ms[1])\n",
    "    secs = mins * 60 + np.float(h_m_s_ms[2])\n",
    "    msecs = secs * 1000 + np.float(h_m_s_ms [3])\n",
    "    \n",
    "    # append msecs to array\n",
    "    udacity_ms_timestamp.append(int(msecs))\n",
    "\n",
    "\n",
    "\n",
    "my_ms_timestamp_norm = ([my_ms_timestamp[i+1]- my_ms_timestamp[i] for i in range(len(my_ms_timestamp)-1)])\n",
    "my_ms_timestamp_norm.insert(0,0)\n",
    "my_ms_timestamp_norm_cum = np.cumsum(my_ms_timestamp_norm)\n",
    "\n",
    "udacity_ms_timestamp_norm = ([udacity_ms_timestamp[i+1]- udacity_ms_timestamp[i] for i in range(len(udacity_ms_timestamp)-1)])\n",
    "udacity_ms_timestamp_norm.insert(0,0)\n",
    "udacity_ms_timestamp_norm_cum = np.cumsum(udacity_ms_timestamp_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "\n",
    "fig = plt.figure(figsize=(12,12))\n",
    "\n",
    "\n",
    "ax1 = plt.subplot(2, 2, 1)\n",
    "\n",
    "plt.plot(my_ms_timestamp_norm_cum, np_my_steering_angles, label='my_data')\n",
    "plt.plot(udacity_ms_timestamp_norm_cum, udacity_steering_angles, label='udacity', alpha=0.5)\n",
    "plt.legend()\n",
    "plt.xlabel('mSecs')\n",
    "plt.ylabel('angle (rad)')\n",
    "plt.title('Steering Wheel Angle Variation')\n",
    "plt.grid(True)\n",
    "\n",
    "ax2 = plt.subplot(2, 2, 2)\n",
    "\n",
    "plt.plot(np_my_steering_angles, label='my_data' )\n",
    "plt.plot(udacity_steering_angles, label='udacity',alpha=0.5)\n",
    "plt.legend()\n",
    "plt.xlabel('instance position')\n",
    "plt.ylabel('angle (rad)')\n",
    "plt.title('Steering Wheel Angle Variation')\n",
    "plt.grid(True)\n",
    "\n",
    "ax3 = plt.subplot(2, 2, 3)\n",
    "#plt.scatter(udacity_ms_timestamp_norm_cum, udacity_steering_angles, label='udacity')\n",
    "plt.scatter(my_ms_timestamp_norm_cum, np_my_steering_angles, label='my_data', alpha=0.5)\n",
    "plt.legend()\n",
    "plt.xlabel('mSecs')\n",
    "plt.ylabel('angle (rad)')\n",
    "plt.title('Steering Wheel Angle Variation')\n",
    "plt.grid(True)\n",
    "\n",
    "ax4 = plt.subplot(2, 2, 4)\n",
    "#plt.scatter(udacity_ms_timestamp_norm_cum, udacity_steering_angles, label='udacity')\n",
    "#plt.hist(my_ms_timestamp_norm_cum, my_steering_angles, label='my_data')\n",
    "\n",
    "plt.hist(np_my_steering_angles, 100, alpha=0.75, label='my_data' )\n",
    "plt.legend()\n",
    "plt.xlabel('angle(rad)')\n",
    "plt.ylabel('Number of instances')\n",
    "plt.title('Steering Wheel Angle Variation')\n",
    "plt.grid(True)\n",
    "\n",
    "\n",
    "#plt.savefig(\"test.png\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "instance_count = len(np_my_steering_angles)\n",
    "num_zeros = ((np_my_steering_angles == 0.0) & (np_my_steering_angles == -0.0)).sum()\n",
    "num_near_zero = ((np_my_steering_angles < 0.0174) & (np_my_steering_angles > -0.0174)).sum()\n",
    "num_left = (np_my_steering_angles < 0.0).sum()\n",
    "num_right = (np_my_steering_angles > 0.0).sum()\n",
    "\n",
    "deg = math.degrees(0.0174)\n",
    "rad = math.radians(1)\n",
    "\n",
    "print(\"Total number of steering instances: {0}\".format(instance_count))\n",
    "print(\"Number of instances with 0 as steering Angle: {0} ({1:.2f}%)\".format(num_zeros, (num_zeros/instance_count)*100))\n",
    "print(\"Number of instances < +/-1 degree as steering Angle: {0} ({1:.2f}%)\".format(num_near_zero, (num_near_zero/instance_count)*100))\n",
    "print(\"Number of instances with left steering Angle: {0} ({1:.2f}%)\".format(num_left, (num_left/instance_count)*100))\n",
    "print(\"Number of instances with right steering Angle: {0} ({1:.2f}%)\".format(num_right, (num_right/instance_count)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "instance_count = len(y_train)\n",
    "image_count = len(X_train)\n",
    "num_zeros = ((y_train == 0.0) & (y_train == -0.0)).sum()\n",
    "num_near_zero = ((y_train < 0.0174) & (y_train > -0.0174)).sum()\n",
    "num_left = (y_train < 0.0).sum()\n",
    "num_right = (y_train > 0.0).sum()\n",
    "\n",
    "deg = math.degrees(0.0174)\n",
    "rad = math.radians(1)\n",
    "\n",
    "print(\"Total number of steering instances: {0}\".format(instance_count))\n",
    "print(\"Total number of image instances: {0}\".format(image_count))\n",
    "print(\"Number of instances with 0 as steering Angle: {0} ({1:.2f}%)\".format(num_zeros, (num_zeros/instance_count)*100))\n",
    "print(\"Number of instances < +/-1 degree as steering Angle: {0} ({1:.2f}%)\".format(num_near_zero, (num_near_zero/instance_count)*100))\n",
    "print(\"Number of instances with left steering Angle: {0} ({1:.2f}%)\".format(num_left, (num_left/instance_count)*100))\n",
    "print(\"Number of instances with right steering Angle: {0} ({1:.2f}%)\".format(num_right, (num_right/instance_count)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Â play video file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from moviepy.editor import ImageSequenceClip\n",
    "import argparse\n",
    "import os\n",
    "\n",
    "IMAGE_EXT = ['jpeg', 'gif', 'png', 'jpg']\n",
    "\n",
    "\n",
    "def video_maker(image_folder='./data/IMG',set_fps=10):\n",
    "\n",
    "    #convert file folder into list filtered for image file types\n",
    "    image_list = sorted([os.path.join(image_folder, image_file)\n",
    "                        for image_file in os.listdir(image_folder)])\n",
    "    \n",
    "    image_list = [image_file for image_file in image_list if os.path.splitext(image_file)[1][1:].lower() in IMAGE_EXT]\n",
    "\n",
    "    #two methods of naming output video to handle varying environemnts\n",
    "    video_file_1 = image_folder + '.mp4'\n",
    "    video_file_2 = image_folder + 'output_video.mp4'\n",
    "\n",
    "    print(\"Creating video {}, FPS={}\".format(image_folder, set_fps))\n",
    "    clip = ImageSequenceClip(image_list, fps=set_fps)\n",
    "    \n",
    "    try:\n",
    "        clip.write_videofile(video_file_1)\n",
    "    except:\n",
    "        clip.write_videofile(video_file_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#video_maker()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NVIDIA NET FUNCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten, Dense, Lambda, Cropping2D, Dropout\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "\n",
    "\n",
    "def net_NVIDIA():\n",
    "    # NVIDIA Convolutional Network function\n",
    "    \n",
    "    # create a sequential model\n",
    "    model = Sequential()\n",
    "\n",
    "\n",
    "    # add pre-processing steps - normalising the data and mean centre the data\n",
    "    # add a lambda layer for normalisation\n",
    "    # normalise image by divide each element by 255 (max value of an image pixel)\n",
    "    model.add(Lambda(lambda x: x / 255.0 - 0.5, input_shape=(160, 320, 3)))\n",
    "    # after image is normalised in a range 0 to 1 - mean centre it by subtracting 0.5 from each element - shifts mean from 0.5 to 0\n",
    "    # training loss and validation loss should be much smaller\n",
    "\n",
    "    # crop the image to remove pixels that are not adding value - top 70, and bottom 25 rows\n",
    "    model.add(Cropping2D(cropping=((70, 25), (0, 0))))\n",
    "\n",
    "    # keras auto infer shape of all layers after 1st layer\n",
    "    # 1st layer\n",
    "    #model.add(Conv2D(24, (5, 5), subsample=(2, 2), activation=\"relu\"))\n",
    "    model.add(Conv2D(24, (5, 5), activation=\"elu\", strides=(2, 2)))\n",
    "    # 2nd layer\n",
    "    #model.add(Conv2D(36, (5, 5), subsample=(2, 2), activation=\"relu\"))\n",
    "    model.add(Conv2D(36, (5, 5), activation=\"elu\", strides=(2, 2)))\n",
    "    # 3rd layer\n",
    "    #model.add(Conv2D(48, (5, 5), subsample=(2, 2), activation=\"relu\"))\n",
    "    model.add(Conv2D(48, (5, 5), activation=\"elu\", strides=(2, 2)))\n",
    "    # 4th layer\n",
    "    model.add(Conv2D(64, (3, 3), activation=\"elu\"))\n",
    "    # 5th layer\n",
    "    model.add(Conv2D(64, (3, 3), activation=\"elu\"))\n",
    "    # 6th layer\n",
    "    model.add(Flatten())\n",
    "    # 7th layer - add fully connected layer ouput of 100\n",
    "    model.add(Dense(100))\n",
    "    # 8th layer - add fully connected layer ouput of 50\n",
    "    model.add(Dense(50))\n",
    "    # 9th layer - add fully connected layer ouput of 10\n",
    "    model.add(Dense(10))\n",
    "    # 0th layer - add fully connected layer ouput of 1\n",
    "    model.add(Dense(1))\n",
    "    \n",
    "    model.summary()\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "def train_model(model, inputs, outputs, model_path, set_epochs= 3):\n",
    "\n",
    "    #model.compile(loss='mse', optimizer='adam')\n",
    "    model.compile(loss='mse', optimizer='adam', metrics=['mse', 'mae', 'mape', 'cosine', 'acc'])\n",
    "    history_object = model.fit(inputs, outputs, validation_split=0.2, shuffle=True, epochs=set_epochs, verbose=1)\n",
    "    \n",
    "    model_object = model_path + 'ELUoldFinal' + str(set_epochs) + '.h5'\n",
    "    model.save(model_object)\n",
    "    print(\"Model saved at \" + model_object)\n",
    "    \n",
    "    return history_object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Model\n",
    "model = net_NVIDIA()\n",
    "num_epoch = 8\n",
    "\n",
    "history_object = train_model(model, X_train, y_train, './NVidia_', num_epoch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "### print the keys contained in the history object\n",
    "print(history_object.history.keys())\n",
    "\n",
    "### plot the training and validation loss for each epoch\n",
    "plt.plot(history_object.history['loss'])\n",
    "plt.plot(history_object.history['val_loss'])\n",
    "\n",
    "plt.title('model mean squared error loss')\n",
    "plt.ylabel('mean squared error loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['training set', 'validation set'], loc='upper right')\n",
    "\n",
    "#plt.savefig(\"Loss_NVidia_6.png\")\n",
    "plt.savefig(\"Final_old_data_elu_Loss_NVidia_{0}.png\".format(num_epoch))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
