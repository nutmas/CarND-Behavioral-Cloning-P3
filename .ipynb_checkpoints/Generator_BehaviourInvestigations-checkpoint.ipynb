{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LOAD DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv # for csv file import\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import math\n",
    "#from keras import optimizers\n",
    "from sklearn.utils import shuffle #Â to shuffle data in generator\n",
    "from sklearn.model_selection import train_test_split # to split data into Training + Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_file_data(file_path, header=False):\n",
    "    # function to read in data from driving_log.csv\n",
    "    \n",
    "    samples = []\n",
    "    with open(file_path + '/driving_log.csv') as csvfile:\n",
    "        reader = csv.reader(csvfile)\n",
    "        # if header is set to true then skip first line of csv\n",
    "        if header:\n",
    "            # if header exists iterate to next item in list, returns -1 if exhausted\n",
    "            next(reader, -1)\n",
    "        for line in reader:\n",
    "            # loop through reader appending each line to samples array\n",
    "            samples.append(line)\n",
    "    return samples\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stats_print(X_train,y_train):\n",
    "\n",
    "\n",
    "    instance_count = len(y_train)\n",
    "    image_count = len(X_train)\n",
    "    num_zeros = ((y_train == 0.0) & (y_train == -0.0)).sum()\n",
    "    num_near_zero = ((y_train < 0.0174) & (y_train > -0.0174)).sum()\n",
    "    num_left = (y_train < 0.0).sum()\n",
    "    num_right = (y_train > 0.0).sum()\n",
    "\n",
    "    deg = math.degrees(0.0174)\n",
    "    rad = math.radians(1)\n",
    "\n",
    "    print(\"Total number of steering instances: {0}\".format(instance_count))\n",
    "    print(\"Total number of image instances: {0}\".format(image_count))\n",
    "    print(\"Number of instances with 0 as steering Angle: {0} ({1:.2f}%)\".format(num_zeros, (num_zeros/instance_count)*100))\n",
    "    print(\"Number of instances < +/-1 degree as steering Angle: {0} ({1:.2f}%)\".format(num_near_zero, (num_near_zero/instance_count)*100))\n",
    "    print(\"Number of instances with left steering Angle: {0} ({1:.2f}%)\".format(num_left, (num_left/instance_count)*100))\n",
    "    print(\"Number of instances with right steering Angle: {0} ({1:.2f}%)\".format(num_right, (num_right/instance_count)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator(samples, batch_size=32):\n",
    "    \"\"\"\n",
    "    Generate the required images and measurments for training/\n",
    "    `samples` is a list of pairs (`imagePath`, `measurement`).\n",
    "    \"\"\"\n",
    "    num_samples = len(samples)\n",
    "    while 1: # Loop forever so the generator never terminates\n",
    "        samples = sklearn.utils.shuffle(samples)\n",
    "        for offset in range(0, num_samples, batch_size):\n",
    "            batch_samples = samples[offset:offset+batch_size]\n",
    "\n",
    "            images = []\n",
    "            angles = []\n",
    "            for imagePath, measurement in batch_samples:\n",
    "                originalImage = cv2.imread(imagePath)\n",
    "                image = cv2.cvtColor(originalImage, cv2.COLOR_BGR2RGB)\n",
    "                images.append(image)\n",
    "                angles.append(measurement)\n",
    "                # Flipping\n",
    "                images.append(cv2.flip(image,1))\n",
    "                angles.append(measurement*-1.0)\n",
    "\n",
    "            # trim image to only see section with road\n",
    "            inputs = np.array(images)\n",
    "            outputs = np.array(angles)\n",
    "            yield sklearn.utils.shuffle(inputs, outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NVIDIA NET FUNCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten, Dense, Lambda, Cropping2D, Dropout\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "\n",
    "\n",
    "def createPreProcessingLayers():\n",
    "    \"\"\"\n",
    "    Creates a model with the initial pre-processing layers.\n",
    "    \"\"\"\n",
    "    model = Sequential()\n",
    "    model.add(Lambda(lambda x: (x / 255.0) - 0.5, input_shape=(160,320,3)))\n",
    "    model.add(Cropping2D(cropping=((50,20), (0,0))))\n",
    "    return model\n",
    "\n",
    "def net_NVIDIA():\n",
    "    # NVIDIA Convolutional Network function\n",
    "    \n",
    "    # create a sequential model\n",
    "    #model = Sequential()\n",
    "\n",
    "\n",
    "    # add pre-processing steps - normalising the data and mean centre the data\n",
    "    # add a lambda layer for normalisation\n",
    "    # normalise image by divide each element by 255 (max value of an image pixel)\n",
    "    #model.add(Lambda(lambda x: x / 255.0 - 0.5, input_shape=(160, 320, 3)))\n",
    "    # after image is normalised in a range 0 to 1 - mean centre it by subtracting 0.5 from each element - shifts mean from 0.5 to 0\n",
    "    # training loss and validation loss should be much smaller\n",
    "\n",
    "    # crop the image to remove pixels that are not adding value - top 70, and bottom 25 rows\n",
    "    #model.add(Cropping2D(cropping=((70, 25), (0, 0))))\n",
    "    model = createPreProcessingLayers()\n",
    "    # keras auto infer shape of all layers after 1st layer\n",
    "    # 1st layer\n",
    "    #model.add(Conv2D(24, (5, 5), subsample=(2, 2), activation=\"relu\"))\n",
    "    model.add(Conv2D(24, (5, 5), activation=\"elu\", strides=(2, 2)))\n",
    "    # 2nd layer\n",
    "    #model.add(Conv2D(36, (5, 5), subsample=(2, 2), activation=\"relu\"))\n",
    "    model.add(Conv2D(36, (5, 5), activation=\"elu\", strides=(2, 2)))\n",
    "    # 3rd layer\n",
    "    #model.add(Conv2D(48, (5, 5), subsample=(2, 2), activation=\"relu\"))\n",
    "    model.add(Conv2D(48, (5, 5), activation=\"elu\", strides=(2, 2)))\n",
    "    # 4th layer\n",
    "    model.add(Conv2D(64, (3, 3), activation=\"elu\"))\n",
    "    # 5th layer\n",
    "    model.add(Conv2D(64, (3, 3), activation=\"elu\"))\n",
    "    # 6th layer\n",
    "    model.add(Flatten())\n",
    "    # 7th layer - add fully connected layer ouput of 100\n",
    "    model.add(Dense(100))\n",
    "    # 8th layer - add fully connected layer ouput of 50\n",
    "    model.add(Dense(50))\n",
    "    # 9th layer - add fully connected layer ouput of 10\n",
    "    model.add(Dense(10))\n",
    "    # 0th layer - add fully connected layer ouput of 1\n",
    "    model.add(Dense(1))\n",
    "    \n",
    "    # summarise neural net and display on screen\n",
    "    model.summary()\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_samples, validation_samples, model_path, set_epochs= 3):\n",
    "\n",
    "    #model.compile(loss='mse', optimizer='adam')\n",
    "    \n",
    "    #adam = optimizers.Adam(lr=0.001)\n",
    "    model.compile(loss='mse', optimizer='Adam', metrics=['mse', 'mae', 'mape', 'cosine', 'acc'])\n",
    "    \n",
    "    \n",
    "    #model.compile(loss='mse', optimizer='adam'(lr=0.001), metrics=['mse', 'mae', 'mape', 'cosine', 'acc'])\n",
    "    #history_object = model.fit(inputs, outputs, validation_split=0.2, shuffle=True, epochs=set_epochs, verbose=1)\n",
    "    \n",
    "    train_generator = generator(train_samples)\n",
    "    #print (train_generator[0])\n",
    "    validation_generator = generator(validation_samples)\n",
    "    \n",
    "    \n",
    "    \n",
    "    history_object=model.fit_generator(train_generator, steps_per_epoch= len(train_samples), validation_data=validation_generator, validation_steps=len(validation_samples), epochs=set_epochs, verbose = 1)\n",
    "    \n",
    "    model_path\n",
    "    \n",
    "    model_object = 'Final_' + model_path + str(set_epochs) + '.h5'\n",
    "    model.save(model_object)\n",
    "    print(\"Model saved at \" + model_object)\n",
    "    \n",
    "    return history_object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['IMG/center_2016_12_01_13_35_31_535.jpg', ' IMG/left_2016_12_01_13_35_31_535.jpg', ' IMG/right_2016_12_01_13_35_31_535.jpg', ' 0.2626991', ' 0.9855326', ' 0', ' 30.18174']\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lambda_10 (Lambda)           (None, 160, 320, 3)       0         \n",
      "_________________________________________________________________\n",
      "cropping2d_10 (Cropping2D)   (None, 90, 320, 3)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_46 (Conv2D)           (None, 43, 158, 24)       1824      \n",
      "_________________________________________________________________\n",
      "conv2d_47 (Conv2D)           (None, 20, 77, 36)        21636     \n",
      "_________________________________________________________________\n",
      "conv2d_48 (Conv2D)           (None, 8, 37, 48)         43248     \n",
      "_________________________________________________________________\n",
      "conv2d_49 (Conv2D)           (None, 6, 35, 64)         27712     \n",
      "_________________________________________________________________\n",
      "conv2d_50 (Conv2D)           (None, 4, 33, 64)         36928     \n",
      "_________________________________________________________________\n",
      "flatten_10 (Flatten)         (None, 8448)              0         \n",
      "_________________________________________________________________\n",
      "dense_37 (Dense)             (None, 100)               844900    \n",
      "_________________________________________________________________\n",
      "dense_38 (Dense)             (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "dense_39 (Dense)             (None, 10)                510       \n",
      "_________________________________________________________________\n",
      "dense_40 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 981,819\n",
      "Trainable params: 981,819\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:28: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:28: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<generator..., validation_data=<generator..., verbose=1, steps_per_epoch=6428, epochs=1, validation_steps=1608)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16086428\n",
      "Epoch 1/1\n",
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected lambda_10_input to have 4 dimensions, but got array with shape (96, 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-d80a8b56d494>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0mvalidation_generator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalidation_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m \u001b[0mhistory_object\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_generator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msamples_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m                  \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_samples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_generator\u001b[0m\u001b[0;34m,\u001b[0m                  \u001b[0mnb_val_samples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalidation_samples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;31m# train the model and save the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     90\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1413\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1414\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1415\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1416\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    211\u001b[0m                 outs = model.train_on_batch(x, y,\n\u001b[1;32m    212\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 213\u001b[0;31m                                             class_weight=class_weight)\n\u001b[0m\u001b[1;32m    214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1207\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1208\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1209\u001b[0;31m             class_weight=class_weight)\n\u001b[0m\u001b[1;32m   1210\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_uses_dynamic_learning_phase\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1211\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1.\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m    747\u001b[0m             \u001b[0mfeed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    748\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 749\u001b[0;31m             exception_prefix='input')\n\u001b[0m\u001b[1;32m    750\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    751\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    125\u001b[0m                         \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m                         \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' dimensions, but got array '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m                         'with shape ' + str(data_shape))\n\u001b[0m\u001b[1;32m    128\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m                     \u001b[0mdata_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking input: expected lambda_10_input to have 4 dimensions, but got array with shape (96, 1)"
     ]
    }
   ],
   "source": [
    "##Â main program\n",
    "\n",
    "import sklearn\n",
    "\n",
    "\n",
    "#samples = get_file_data('./my_driving')\n",
    "data_samples = get_file_data('./data')\n",
    "#print(data_samples[0])\n",
    "\n",
    "# Split dataset: 80% training; 20% validation\n",
    "train_samples, validation_samples = train_test_split(data_samples, test_size=0.2)\n",
    "\n",
    "\n",
    "#X_train_gen, y_train_gen = generator(data_samples)\n",
    "\n",
    "print(train_samples[0])\n",
    "\n",
    "\n",
    "# Create Model\n",
    "model = net_NVIDIA() #input_shape=(160, 320, 3)\n",
    "num_epoch = 1\n",
    "\n",
    "model.compile(loss='mse', optimizer='adam', metrics=['mse', 'mae', 'mape', 'cosine', 'acc'])\n",
    "\n",
    "train_generator = generator(train_samples, batch_size=32)\n",
    "validation_generator = generator(validation_samples, batch_size=32)\n",
    "\n",
    "history_object = model.fit_generator(train_generator, samples_per_epoch= \\\n",
    "                 len(train_samples), validation_data=validation_generator, \\\n",
    "                 nb_val_samples=len(validation_samples), nb_epoch=1, verbose=1)\n",
    "\n",
    "# train the model and save the model\n",
    "#history_object = train_model(model, train_samples, validation_samples, './Gen_NVidia_', num_epoch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "### print the keys contained in the history object\n",
    "print(history_object.history.keys())\n",
    "\n",
    "### plot the training and validation loss for each epoch\n",
    "plt.plot(history_object.history['loss'])\n",
    "plt.plot(history_object.history['val_loss'])\n",
    "\n",
    "plt.title('model mean squared error loss')\n",
    "plt.ylabel('mean squared error loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['training set', 'validation set'], loc='upper right')\n",
    "\n",
    "#plt.savefig(\"Loss_NVidia_6.png\")\n",
    "plt.savefig(\"Final_Loss_NVidia_{0}.png\".format(num_epochs))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
